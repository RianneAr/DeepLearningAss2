{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c684b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 13:36:48.599737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist, cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61369df",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "First, we load in the data and split it into a train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07664251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14400, 150, 150, 1)\n",
      "14400 train samples\n",
      "3600 test samples\n"
     ]
    }
   ],
   "source": [
    "# load the grayscale images and two-interger labels\n",
    "images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# the data, split between train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 150, 150\n",
    "\n",
    "# reshape the 2D input data to 4D to fit the conv2D layer\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0230e1",
   "metadata": {},
   "source": [
    "## Definition of common-sense difference\n",
    "\n",
    "The difference between the predicted time and actual time will be quantified using the 'common-sense' time. The function that calculates this time difference is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abd1a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 1:  [ 0 20] \n",
      "Time 2:  [11 40] \n",
      "Difference in minutes:  40\n"
     ]
    }
   ],
   "source": [
    "def common_sense(time1, time2):\n",
    "    time1min = time1[0]*60 + time1[1]\n",
    "    time2min = time2[0]*60 + time2[1]\n",
    "    \n",
    "    diff = abs(time1min - time2min)\n",
    "    csdiff = min(diff, 12*60-diff)\n",
    "    csdiffhr = np.array([int(csdiff/60), csdiff%60])\n",
    "    \n",
    "    return csdiff\n",
    "\n",
    "print('Time 1: ', labels[500], '\\nTime 2: ', labels[17500], '\\nDifference in minutes: ', common_sense(labels[500], labels[17500]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee107b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 24 # maximum 720\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde9e76",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the two-interger labels to a float\n",
    "y_reg_train = y_train[:, 0] + y_train[:, 1] / 60\n",
    "y_reg_test = y_test[:, 0] + y_test[:, 1] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3a1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the common sense accuracy for regression model\n",
    "def common_sense_reg(y_true, y_pred):\n",
    "    print(y_true, y_pred)\n",
    "    differences = K.abs(y_pred - y_true)\n",
    "    diff = tf.math.minimum(differences, tf.subtract(12.0, differences))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3881f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, padding=\"SAME\", input_shape=input_shape) \n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape)) # , activation='relu'\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer='sgd', metrics=[common_sense_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b5dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      " 39/144 [=======>......................] - ETA: 4:08 - loss: 14.5235 - common_sense_reg: -5.1493"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_reg_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, y_reg_test))\n",
    "score = model.evaluate(X_test, y_reg_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dccf52",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "811329a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the two-interger labels to 24 classes\n",
    "def classification_label(y):\n",
    "    label = []\n",
    "    for i in y:\n",
    "        if i[1] <= 30:\n",
    "            label.append(2 * i[0] +1)\n",
    "        else:\n",
    "            label.append(2 * i[0] +2)\n",
    "    return label\n",
    "y_class_train = classification_label(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the common sense accuracy for classification model\n",
    "def common_sense_reg(y_true, y_pred):\n",
    "    differences = K.abs(y_pred - y_true)\n",
    "    diff = tf.math.minimum(differences, tf.subtract(12.0, differences))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b55d18",
   "metadata": {},
   "source": [
    "## Multi-head models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91b35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0888745",
   "metadata": {},
   "source": [
    "## Optimizing final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd0f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
